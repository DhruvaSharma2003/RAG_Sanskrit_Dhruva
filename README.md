# ğŸ•‰ï¸ Sanskrit RAG System  
### **Retrieval-Augmented Generation using Qwen2.5â€“1.5B & Local Knowledge Base**  
**Author:** Dhruva Sharma  
**Project Type:** AI/ML Intern Assessment  
**Model:** Qwen2.5â€“1.5B Instruct (Local, Offline CPU Mode)  
**Embeddings:** Multilingual-e5-small  
**Retrievers:** FAISS Vector Search + TFâ€“IDF Keyword Search  

---

## ğŸ“– Project Overview

This project implements a **Retrieval-Augmented Generation (RAG) system** for answering questions from **Sanskrit classical texts**.  

Instead of using an online LLM API, the system uses a **completely offline local model (Qwen2.5â€“1.5B-Instruct)** along with:

- A local **knowledge base** (DOCX / PDF Sanskrit documents)
- Text **chunking** + preprocessing
- **Sentence Transformer embeddings**  
- **FAISS** vector similarity search  
- A Streamlit-based UI for querying the system  

The final pipeline performs:

1. **Document loading** (DOCX and PDF supported)  
2. **Chunking & preprocessing**  
3. **Embedding generation**  
4. **Vector + keyword retrieval**  
5. **LLM-based answer generation using only retrieved context**  

This ensures that the LLM **does not hallucinate** and answers only from provided Sanskrit sources.

---

## ğŸ”¥ Features

âœ” Fully offline RAG system  
âœ” Accurate chunk-based retrieval  
âœ” Sanskrit-compatible DOCX loader  
âœ” Streamlit UI for interactive querying  
âœ” Supports vector + TF-IDF keyword search  
âœ” Lightweight Qwen model runs on CPU  
âœ” Works with long classical Sanskrit passages  
âœ” Clean and modular code structure  

---

## ğŸ“ Folder Structure

RAG_Sanskrit_Dhruva/
â”‚
â”œâ”€â”€ code/
â”‚ â”œâ”€â”€ app.py # Streamlit UI
â”‚ â”œâ”€â”€ rag_pipeline.py # Full RAG pipeline
â”‚ â”œâ”€â”€ generator.py # Qwen2.5-1.5B answer generator
â”‚ â”œâ”€â”€ loader.py # DOCX/PDF loading
â”‚ â”œâ”€â”€ preprocessing.py # Chunking
â”‚ â”œâ”€â”€ embedder.py # Embedding model (E5-small)
â”‚ â”œâ”€â”€ retriever.py # FAISS & TF-IDF retrievers
â”‚
â”œâ”€â”€ models/
â”‚ â””â”€â”€ qwen1.5b/ # Local LLM files (NOT uploaded to GitHub)
â”‚
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Input Sanskrit PDFs/DOCX
â”‚ â””â”€â”€ processed/
â”‚ â”œâ”€â”€ chunks.json # Preprocessed text chunks
â”‚ â””â”€â”€ embeddings.npy # Vector embeddings
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

yaml
Copy code

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/YOUR_USERNAME/RAG_Sanskrit_Dhruva.git
cd RAG_Sanskrit_Dhruva
2ï¸âƒ£ Create & activate virtual environment
bash
Copy code
python -m venv venv
venv\Scripts\activate
3ï¸âƒ£ Install dependencies
bash
Copy code
pip install -r requirements.txt
ğŸ§  Download the Qwen Model (Required)
You MUST download the model locally before running the app.

Run inside the project folder:

bash
Copy code
hf download Qwen/Qwen2.5-1.5B-Instruct \
    --local-dir models/qwen1.5b \
    --include "*.json" "*.model" "*.safetensors"
âš ï¸ Do NOT upload the model files to GitHub.
They exceed size limits and are meant to remain local only.

ğŸ—‚ Preparing the Knowledge Base
Place your Sanskrit files in:

bash
Copy code
data/raw/
Supported formats:

.docx (recommended â€” preserves Devanagari correctly)

.pdf

.txt

After placing files, delete old processed files:

bash
Copy code
data/processed/chunks.json
data/processed/embeddings.npy
They will be regenerated automatically.

ğŸš€ Running the App
Run Streamlit:

bash
Copy code
python -m streamlit run code/app.py
Open in browser:

arduino
Copy code
http://localhost:8501
You will see:

Query input box

Retrieval method selector

Top-3 retrieved chunks

Generated answer from Qwen model

ğŸ§ª Example Query
Copy code
à¤­à¥‹à¤œà¤°à¤¾à¤œà¥à¤à¤¾ à¤•à¤¿à¤¯à¤¦à¥ à¤§à¤¨à¤‚ à¤•à¤µà¤¯à¥‡ à¤¦à¤¾à¤¤à¥à¤®à¥ à¤˜à¥‹à¤·à¤¿à¤¤à¤µà¤¾à¤¨à¥ ?
Expected Answer:

Copy code
à¤­à¥‹à¤œà¤°à¤¾à¤œà¥à¤à¤¾ à¤²à¤•à¥à¤·à¤°à¥à¤ªà¥à¤¯à¤•à¤¾à¤£à¤¿ à¤¦à¤¾à¤¤à¥à¤®à¥ à¤˜à¥‹à¤·à¤¿à¤¤à¤µà¤¾à¤¨à¥à¥¤
ğŸ§¬ Internal Architecture
1. Loader
Reads DOCX, PDF, TXT

Extracts Unicode Sanskrit text

2. Preprocessor
Cleans text

Splits into chunks (size 256â€“300 tokens)

3. Embedder
Uses intfloat/multilingual-e5-small

Generates dense embeddings for each chunk

4. Retriever
FAISS L2 search

TF-IDF fallback keyword search

5. Generator
Qwen2.5â€“1.5B-Instruct

Strict â€œcontext-only answeringâ€ prompt

Offline CPU inference
